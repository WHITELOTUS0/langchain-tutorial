{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt use case:\n",
        "\n",
        "A key feature of LangChain is its support for prompts, which encompasses prompt management, prompt optimization, and a generic interface for all LLMs. The framework also provides common utilities for working with LLMs.\n",
        "\n",
        "`ChatPromptTemplate` is used to create a structured conversation with the AI model, making it easier to manage the flow and content of the conversation. In LangChain, message prompt templates are used to construct and work with prompts, allowing us to exploit the underlying chat model's potential fully.\n",
        "\n",
        "System and Human prompts differ in their roles and purposes when interacting with chat models. `SystemMessagePromptTemplate` provides initial instructions, context, or data for the AI model, while `HumanMessagePromptTemplate` are messages from the user that the AI model responds to.\n",
        "\n",
        "To illustrate it, let’s create a chat-based assistant that helps users find information about movies. Ensure your OpenAI key is stored in environment variables using the “OPENAI_API_KEY” name. Remember to install the required packages with the following command:"
      ],
      "metadata": {
        "id": "0gPn6XPO6XZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y53Fu3Sk4Hoc",
        "outputId": "52bb6463-ccaf-4b71-a299-ecdf77375827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-text-splitters\n",
        "!pip install -qU langchain-openai\n",
        "!pip install -qU langchain-community\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "# Before executing the following code, make sure to have\n",
        "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
        "# Get the API key from Colab's userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set it as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "template = \"You are an assistant that helps users find information about movies.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template = \"Find information about the movie {movie_title}.\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "response = chat.invoke(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QePRUlWe7D1_",
        "outputId": "4d189a35-8026-4697-b3c5-7fa7ffe22bf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Inception\" is a science fiction film released in 2010, written and directed by Christopher Nolan. The film stars Leonardo DiCaprio as Dom Cobb, a skilled thief who specializes in the art of \"extraction,\" which involves stealing secrets from within the subconscious during the dream state. The plot revolves around Cobb being offered a chance to have his criminal history erased if he can successfully perform \"inception,\" the act of planting an idea into someone's mind without them realizing it.\n",
            "\n",
            "Key details about the film include:\n",
            "\n",
            "- **Cast**: Alongside DiCaprio, the film features an ensemble cast that includes Joseph Gordon-Levitt, Ellen Page (now Elliot Page), Tom Hardy, Ken Watanabe, Cillian Murphy, Marion Cotillard, and Michael Caine.\n",
            "\n",
            "- **Themes**: \"Inception\" explores complex themes such as the nature of reality, dreams versus waking life, and the power of the subconscious. It raises questions about perception, memory, and the impact of ideas.\n",
            "\n",
            "- **Visual Effects**: The film is renowned for its groundbreaking visual effects, including the iconic scenes of bending cityscapes and gravity-defying action sequences.\n",
            "\n",
            "- **Music**: The score was composed by Hans Zimmer, and the film's music plays a significant role in building tension and emotion throughout the narrative.\n",
            "\n",
            "- **Critical Reception**: \"Inception\" received widespread acclaim from critics and audiences alike, praised for its originality, direction, screenplay, and performances. It was a commercial success, grossing over $800 million worldwide.\n",
            "\n",
            "- **Awards**: The film won four Academy Awards, including Best Cinematography, Best Visual Effects, Best Sound Editing, and Best Sound Mixing. It was also nominated for Best Picture and Best Original Screenplay.\n",
            "\n",
            "\"Inception\" has since become a cultural phenomenon, often discussed for its intricate plot and philosophical implications, and it remains one of Christopher Nolan's most celebrated works.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `to_messages` object in LangChain allows you to convert the formatted value of a chat prompt template into a list of message objects. This is useful when working with chat models, as it provides a structured way to manage the conversation and ensures that the chat model can understand the context and roles of the messages."
      ],
      "metadata": {
        "id": "oS6hSizJ9e59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization chain example:\n",
        "LangChain prompts can be found in various use cases, such as summarization or question-answering chains. For example, when creating a **summarization chain**, LangChain enables interaction with an external data source to fetch data for use in the generation step. This could involve summarizing a lengthy piece of text or answering questions using specific data sources.\n",
        "\n",
        "The following code will initialize the language model using `OpenAI` class with a temperature of 0 - because we want deterministic output.  The load_summarize_chain function accepts an instance of the language model and returns a pre-built summarization chain. Lastly, the `PyPDFLoader` class is responsible for loading PDF files and converting them into a format suitable for processing by LangChain."
      ],
      "metadata": {
        "id": "ozNyZYAR95gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Load the summarization chain\n",
        "summarize_chain = load_summarize_chain(llm)\n",
        "\n",
        "# Load the document using PyPDFLoader\n",
        "document_loader = PyPDFLoader(file_path=\"mypdf.pdf\")\n",
        "document = document_loader.load()\n",
        "\n",
        "# Summarize the document\n",
        "summary = summarize_chain(document)\n",
        "print(summary['output_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYW63jTf-jdt",
        "outputId": "d7008ba4-331a-4574-88c2-9b2eef7c30ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8704a47912ba>:19: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  summary = summarize_chain(document)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \"One Page Linux Manual\" provides a comprehensive overview of essential Linux commands, organized into categories such as starting and stopping the system, accessing and mounting file systems, finding files, managing files, installing software, user administration, and configuration files. Key commands include:\n",
            "\n",
            "- **System Management**: `shutdown`, `reboot`, `halt`, `startx`.\n",
            "- **File System Management**: `mount`, `umount`, `find`, `locate`, `grep`.\n",
            "- **File Operations**: `ls`, `rm`, `cp`, `mv`, `cat`, `head`, `tail`.\n",
            "- **Software Installation**: `rpm` commands for installing, upgrading, and removing packages, and `tar` for decompressing archives.\n",
            "- **User Management**: `adduser`, `passwd`, `su`, `exit`.\n",
            "- **Network and System Utilities**: `ifconfig`, `ps`, `kill`, and various configuration files like `/etc/fstab` and `/etc/hosts`.\n",
            "- **File Permissions**: Explained using `chmod` with octal codes.\n",
            "- **X Window System**: Commands for configuring and tuning X graphics.\n",
            "- **Printing**: Commands for managing print jobs and the print daemon.\n",
            "\n",
            "The manual also includes tips, wildcards for file operations, and shortcuts for X Window operations, making it a handy reference for Linux users.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QA chain example:\n",
        "We can also use LangChain to manage prompts for asking general questions from the LLMs. These models are proficient in addressing fundamental inquiries. Nevertheless, it is crucial to remain mindful of the potential issue of hallucinations, where the models may generate non-factual information. To address this concern, we will later introduce the Retrieval chain as a means to overcome this problem."
      ],
      "metadata": {
        "id": "Z-U178JPAbHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "gCzGqIn0AZ_-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a custom prompt template by creating an instance of the `PromptTemplate` class. The template string contains a placeholder `{question}` for the input question, followed by a newline character and the \"Answer:\" label.  The `input_variables` argument is set to the list of available placeholders in the prompt (like a question in this case) to indicate the name of the variable that the chain will replace in the template.`invoke()` method.\n",
        "\n",
        "We then instantiate an OpenAI model named `gpt-3.5-turbo` with a temperature of 0. The `OpenAI` class is used to create the instance, and the `model_name` and `temperature` arguments are provided. Finally, we create a question-answering chain using the `pipe` operator.\n",
        "\n",
        "The class constructor takes two arguments: `llm`, which is the instantiated `OpenAI` model, and `prompt`, which is the custom prompt template we defined earlier.\n",
        "\n",
        "By following these steps, we can process input questions effectively with the custom question-answering, generating appropriate answers using the OpenAI model and the custom prompt template."
      ],
      "metadata": {
        "id": "F6imkIqVAk9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"what is the meaning of life?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "3KZ7zeTHBHag",
        "outputId": "3aff0941-8bc4-4577-d144-05fed98c5def"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The meaning of life is a profound and often subjective question that has been explored by philosophers, theologians, scientists, and thinkers throughout history. Different cultures and individuals may find meaning through various avenues, such as relationships, personal fulfillment, love, creativity, spirituality, or contributing to the greater good. Ultimately, the meaning of life can vary greatly from person to person, and many believe it is something each individual must define for themselves based on their experiences, beliefs, and values.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}